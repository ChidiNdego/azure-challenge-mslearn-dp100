{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work with Data\n",
    "\n",
    "Data is the foundation on which machine learning models are built. Managing data centrally in the cloud, and making it accessible to teams of data scientists who are running experiments and training models on multiple workstations and compute targets is an important part of any professional data science solution.\n",
    "\n",
    "In this notebook, you'll explore two Azure Machine Learning objects for working with data: *datastores*, and *datasets*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to your workspace\n",
    "\n",
    "To get started, connect to your workspace.\n",
    "\n",
    "> **Note**: If you haven't already established an authenticated session with your Azure subscription, you'll be prompted to authenticate by clicking a link, entering an authentication code, and signing into Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.22.0 to work with azure_ds_challenge\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work with datastores\n",
    "\n",
    "In Azure ML, *datastores* are references to storage locations, such as Azure Storage blob containers. Every workspace has a default datastore - usually the Azure storage blob container that was created with the workspace. If you need to work with data that is stored in different locations, you can add custom datastores to your workspace and set any of them to be the default.\n",
    "\n",
    "### View datastores\n",
    "\n",
    "Run the following code to determine the datastores in your workspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml_globaldatasets - Default = False\n",
      "workspacefilestore - Default = False\n",
      "workspaceblobstore - Default = True\n"
     ]
    }
   ],
   "source": [
    "# Get the default datastore\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "# Enumerate all datastores, indicating which is the default\n",
    "for ds_name in ws.datastores:\n",
    "    print(ds_name, \"- Default =\", ds_name == default_ds.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra note:\n",
    "\n",
    "#### Considerations for datastores\n",
    "\n",
    "When planning for datastores, consider the following guidelines:\n",
    "\n",
    "    When using Azure blob storage, premium level storage may provide improved I/O performance for large datasets. However, this option will increase cost and may limit replication options for data redundancy.\n",
    "    When working with data files, although CSV format is very common, Parquet format generally results in better performance.\n",
    "    You can access any datastore by name, but you may want to consider changing the default datastore (which is initially the built-in workspaceblobstore datastore).\n",
    "\n",
    "To change the default datastore, use the set_default_datastore() method:\n",
    "\n",
    "```\n",
    "ws.set_default_datastore('blob_data')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also view and manage datastores in your workspace on the **Datastores** page for your workspace in [Azure Machine Learning studio](https://ml.azure.com).\n",
    "\n",
    "### Upload data to a datastore\n",
    "\n",
    "Now that you have determined the available datastores, you can upload files from your local file system to a datastore so that it will be accessible to experiments running in the workspace, regardless of where the experiment script is actually being run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 2 files\n",
      "Uploading ./data/diabetes.csv\n",
      "Uploaded ./data/diabetes.csv, 1 files out of an estimated total of 2\n",
      "Uploading ./data/diabetes2.csv\n",
      "Uploaded ./data/diabetes2.csv, 2 files out of an estimated total of 2\n",
      "Uploaded 2 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_d1dbd37676fe4f58813b0c6646dbad58"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_ds.upload_files(files=['./data/diabetes.csv', './data/diabetes2.csv'], # Upload the diabetes csv files in /data\n",
    "                       target_path='diabetes-data/', # Put it in a folder path in the datastore\n",
    "                       overwrite=True, # Replace existing files of the same name\n",
    "                       show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work with datasets\n",
    "\n",
    "Azure Machine Learning provides an abstraction for data in the form of *datasets*. A dataset is a versioned reference to a specific set of data that you may want to use in an experiment. Datasets can be *tabular* or *file*-based.\n",
    "\n",
    "### Create a tabular dataset\n",
    "\n",
    "Let's create a dataset from the diabetes data you uploaded to the datastore, and view the first 20 records. In this case, the data is in a structured format in a CSV file, so we'll use a *tabular* dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>PlasmaGlucose</th>\n",
       "      <th>DiastolicBloodPressure</th>\n",
       "      <th>TricepsThickness</th>\n",
       "      <th>SerumInsulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigree</th>\n",
       "      <th>Age</th>\n",
       "      <th>Diabetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1354778</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>80</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "      <td>43.509726</td>\n",
       "      <td>1.213191</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1147438</td>\n",
       "      <td>8</td>\n",
       "      <td>92</td>\n",
       "      <td>93</td>\n",
       "      <td>47</td>\n",
       "      <td>36</td>\n",
       "      <td>21.240576</td>\n",
       "      <td>0.158365</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1640031</td>\n",
       "      <td>7</td>\n",
       "      <td>115</td>\n",
       "      <td>47</td>\n",
       "      <td>52</td>\n",
       "      <td>35</td>\n",
       "      <td>41.511523</td>\n",
       "      <td>0.079019</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1883350</td>\n",
       "      <td>9</td>\n",
       "      <td>103</td>\n",
       "      <td>78</td>\n",
       "      <td>25</td>\n",
       "      <td>304</td>\n",
       "      <td>29.582192</td>\n",
       "      <td>1.282870</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1424119</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>59</td>\n",
       "      <td>27</td>\n",
       "      <td>35</td>\n",
       "      <td>42.604536</td>\n",
       "      <td>0.549542</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1619297</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>92</td>\n",
       "      <td>9</td>\n",
       "      <td>253</td>\n",
       "      <td>19.724160</td>\n",
       "      <td>0.103424</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1660149</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>47</td>\n",
       "      <td>19</td>\n",
       "      <td>227</td>\n",
       "      <td>21.941357</td>\n",
       "      <td>0.174160</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1458769</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>87</td>\n",
       "      <td>43</td>\n",
       "      <td>36</td>\n",
       "      <td>18.277723</td>\n",
       "      <td>0.236165</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1201647</td>\n",
       "      <td>8</td>\n",
       "      <td>80</td>\n",
       "      <td>95</td>\n",
       "      <td>33</td>\n",
       "      <td>24</td>\n",
       "      <td>26.624929</td>\n",
       "      <td>0.443947</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1403912</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>31</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>36.889576</td>\n",
       "      <td>0.103944</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1943830</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>86</td>\n",
       "      <td>11</td>\n",
       "      <td>58</td>\n",
       "      <td>43.225041</td>\n",
       "      <td>0.230285</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1824483</td>\n",
       "      <td>3</td>\n",
       "      <td>94</td>\n",
       "      <td>96</td>\n",
       "      <td>31</td>\n",
       "      <td>36</td>\n",
       "      <td>21.294479</td>\n",
       "      <td>0.259020</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1848869</td>\n",
       "      <td>5</td>\n",
       "      <td>114</td>\n",
       "      <td>101</td>\n",
       "      <td>43</td>\n",
       "      <td>70</td>\n",
       "      <td>36.495320</td>\n",
       "      <td>0.079190</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1669231</td>\n",
       "      <td>7</td>\n",
       "      <td>110</td>\n",
       "      <td>82</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>36.089293</td>\n",
       "      <td>0.281276</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1683688</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>58</td>\n",
       "      <td>11</td>\n",
       "      <td>179</td>\n",
       "      <td>39.192076</td>\n",
       "      <td>0.160829</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1738587</td>\n",
       "      <td>3</td>\n",
       "      <td>109</td>\n",
       "      <td>77</td>\n",
       "      <td>46</td>\n",
       "      <td>61</td>\n",
       "      <td>19.847312</td>\n",
       "      <td>0.204345</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1884264</td>\n",
       "      <td>3</td>\n",
       "      <td>106</td>\n",
       "      <td>64</td>\n",
       "      <td>25</td>\n",
       "      <td>51</td>\n",
       "      <td>29.044573</td>\n",
       "      <td>0.589188</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1485251</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>53</td>\n",
       "      <td>15</td>\n",
       "      <td>226</td>\n",
       "      <td>29.786192</td>\n",
       "      <td>0.203824</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1536832</td>\n",
       "      <td>8</td>\n",
       "      <td>117</td>\n",
       "      <td>39</td>\n",
       "      <td>32</td>\n",
       "      <td>164</td>\n",
       "      <td>21.230996</td>\n",
       "      <td>0.089363</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1438701</td>\n",
       "      <td>3</td>\n",
       "      <td>102</td>\n",
       "      <td>100</td>\n",
       "      <td>25</td>\n",
       "      <td>289</td>\n",
       "      <td>42.185720</td>\n",
       "      <td>0.175593</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PatientID  Pregnancies  PlasmaGlucose  DiastolicBloodPressure  \\\n",
       "0     1354778            0            171                      80   \n",
       "1     1147438            8             92                      93   \n",
       "2     1640031            7            115                      47   \n",
       "3     1883350            9            103                      78   \n",
       "4     1424119            1             85                      59   \n",
       "5     1619297            0             82                      92   \n",
       "6     1660149            0            133                      47   \n",
       "7     1458769            0             67                      87   \n",
       "8     1201647            8             80                      95   \n",
       "9     1403912            1             72                      31   \n",
       "10    1943830            1             88                      86   \n",
       "11    1824483            3             94                      96   \n",
       "12    1848869            5            114                     101   \n",
       "13    1669231            7            110                      82   \n",
       "14    1683688            0            148                      58   \n",
       "15    1738587            3            109                      77   \n",
       "16    1884264            3            106                      64   \n",
       "17    1485251            1            156                      53   \n",
       "18    1536832            8            117                      39   \n",
       "19    1438701            3            102                     100   \n",
       "\n",
       "    TricepsThickness  SerumInsulin        BMI  DiabetesPedigree  Age  Diabetic  \n",
       "0                 34            23  43.509726          1.213191   21         0  \n",
       "1                 47            36  21.240576          0.158365   23         0  \n",
       "2                 52            35  41.511523          0.079019   23         0  \n",
       "3                 25           304  29.582192          1.282870   43         1  \n",
       "4                 27            35  42.604536          0.549542   22         0  \n",
       "5                  9           253  19.724160          0.103424   26         0  \n",
       "6                 19           227  21.941357          0.174160   21         0  \n",
       "7                 43            36  18.277723          0.236165   26         0  \n",
       "8                 33            24  26.624929          0.443947   53         1  \n",
       "9                 40            42  36.889576          0.103944   26         0  \n",
       "10                11            58  43.225041          0.230285   22         0  \n",
       "11                31            36  21.294479          0.259020   23         0  \n",
       "12                43            70  36.495320          0.079190   38         1  \n",
       "13                16            44  36.089293          0.281276   25         0  \n",
       "14                11           179  39.192076          0.160829   45         0  \n",
       "15                46            61  19.847312          0.204345   21         1  \n",
       "16                25            51  29.044573          0.589188   42         1  \n",
       "17                15           226  29.786192          0.203824   41         1  \n",
       "18                32           164  21.230996          0.089363   25         0  \n",
       "19                25           289  42.185720          0.175593   43         1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "# Get the default datastore\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "#Create a tabular dataset from the path on the datastore (this may take a short while)\n",
    "tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
    "\n",
    "# Display the first 20 rows as a Pandas dataframe\n",
    "tab_data_set.take(20).to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Types of dataset\n",
    "\n",
    "Datasets are typically based on files in a datastore, though they can also be based on URLs and other sources. You can create the following types of dataset:\n",
    "\n",
    "    Tabular: The data is read from the dataset as a table. You should use this type of dataset when your data is consistently structured and you want to work with it in common tabular data structures, such as Pandas dataframes.\n",
    "    File: The dataset presents a list of file paths that can be read as though from the file system. Use this type of dataset when your data is unstructured, or when you need to process the data at the file level (for example, to train a convolutional neural network from a set of image files).\n",
    "\n",
    "#### Creating and registering datasets\n",
    "\n",
    "You can use the visual interface in Azure Machine Learning studio or the Azure Machine Learning SDK to create datasets from individual files or multiple file paths. The paths can include wildcards (for example, /files/*.csv) making it possible to encapsulate data from a large number of files in a single dataset.\n",
    "\n",
    "After you've created a dataset, you can register it in the workspace to make it available for use in experiments and data processing pipelines later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the code above, it's easy to convert a tabular dataset to a Pandas dataframe, enabling you to work with the data using common python techniques.\n",
    "\n",
    "### Create a file Dataset\n",
    "\n",
    "The dataset you created is a *tabular* dataset that can be read as a dataframe containing all of the data in the structured files that are included in the dataset definition. This works well for tabular data, but in some machine learning scenarios you might need to work with data that is unstructured; or you may simply want to handle reading the data from files in your own code. To accomplish this, you can use a *file* dataset, which creates a list of file paths in a virtual mount point, which you can use to read the data in the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/diabetes.csv\n",
      "/diabetes2.csv\n"
     ]
    }
   ],
   "source": [
    "#Create a file dataset from the path on the datastore (this may take a short while)\n",
    "file_data_set = Dataset.File.from_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
    "\n",
    "# Get the files in the dataset\n",
    "for file_path in file_data_set.to_path():\n",
    "    print(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register datasets\n",
    "\n",
    "Now that you have created datasets that reference the diabetes data, you can register them to make them easily accessible to any experiment being run in the workspace.\n",
    "\n",
    "We'll register the tabular dataset as **diabetes dataset**, and the file dataset as **diabetes files**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets registered\n"
     ]
    }
   ],
   "source": [
    "# Register the tabular dataset\n",
    "try:\n",
    "    tab_data_set = tab_data_set.register(workspace=ws, \n",
    "                                        name='diabetes dataset',\n",
    "                                        description='diabetes data',\n",
    "                                        tags = {'format':'CSV'},\n",
    "                                        create_new_version=True)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "\n",
    "# Register the file dataset\n",
    "try:\n",
    "    file_data_set = file_data_set.register(workspace=ws,\n",
    "                                            name='diabetes file dataset',\n",
    "                                            description='diabetes files',\n",
    "                                            tags = {'format':'CSV'},\n",
    "                                            create_new_version=True)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "\n",
    "print('Datasets registered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving a registered dataset\n",
    "\n",
    "After registering a dataset, you can retrieve it by using any of the following techniques:\n",
    "\n",
    "    The datasets dictionary attribute of a Workspace object.\n",
    "    The get_by_name or get_by_id method of the Dataset class.\n",
    "\n",
    "Both of these techniques are shown in the following code:\n",
    "\n",
    "```\n",
    "import azureml.core\n",
    "from azureml.core import Workspace, Dataset\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# Get a dataset from the workspace datasets collection\n",
    "ds1 = ws.datasets['csv_table']\n",
    "\n",
    "# Get a dataset by name from the datasets class\n",
    "ds2 = Dataset.get_by_name(ws, 'img_files')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view and manage datasets on the **Datasets** page for your workspace in [Azure Machine Learning studio](https://ml.azure.com). You can also get a list of datasets from the workspace object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets:\n",
      "\t diabetes file dataset version 1\n",
      "\t diabetes dataset version 1\n",
      "\t TD-Auto_Price_Training-Clean_Missing_Data-Cleaning_transformation-91e1ac5f version 1\n",
      "\t TD-Auto_Price_Training-Normalize_Data-Transformation_function-0f39eb1a version 1\n",
      "\t MD-Auto_Price_Training-Train_Model-Trained_model-559e7cee version 1\n",
      "\t bike-rentals version 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Datasets:\")\n",
    "for dataset_name in list(ws.datasets.keys()):\n",
    "    dataset = Dataset.get_by_name(ws, dataset_name)\n",
    "    print(\"\\t\", dataset.name, 'version', dataset.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset versioning\n",
    "\n",
    "Datasets can be versioned, enabling you to track historical versions of datasets that were used in experiments, and reproduce those experiments with data in the same state.\n",
    "\n",
    "You can create a new version of a dataset by registering it with the same name as a previously registered dataset and specifying the create_new_version property:\n",
    "\n",
    "```\n",
    "img_paths = [(blob_ds, 'data/files/images/*.jpg'),\n",
    "             (blob_ds, 'data/files/images/*.png')]\n",
    "file_ds = Dataset.File.from_files(path=img_paths)\n",
    "file_ds = file_ds.register(workspace=ws, name='img_files', create_new_version=True)\n",
    "```\n",
    "\n",
    "In this example, the .png files in the images folder have been added to the definition of the img_paths dataset example used in the previous topic.\n",
    "\n",
    "\n",
    "#### Retrieving a specific dataset version\n",
    "\n",
    "You can retrieve a specific version of a dataset by specifying the version parameter in the get_by_name method of the Dataset class.\n",
    "\n",
    "```\n",
    "img_ds = Dataset.get_by_name(workspace=ws, name='img_files', version=2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ability to version datasets enables you to redefine datasets without breaking existing experiments or pipelines that rely on previous definitions. By default, the latest version of a named dataset is returned, but you can retrieve a specific version of a dataset by specifying the version number, like this:\n",
    "\n",
    "```python\n",
    "dataset_v1 = Dataset.get_by_name(ws, 'diabetes dataset', version = 1)\n",
    "```\n",
    "\n",
    "\n",
    "### Train a model from a tabular dataset\n",
    "\n",
    "Now that you have datasets, you're ready to start training models from them. You can pass datasets to scripts as *inputs* in the estimator being used to run the script.\n",
    "\n",
    "Run the following two code cells to create:\n",
    "\n",
    "1. A folder named **diabetes_training_from_tab_dataset**\n",
    "2. A script that trains a classification model by using a tabular dataset that is passed to is as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_training_from_tab_dataset folder created\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "experiment_folder = 'diabetes_training_from_tab_dataset'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "print(experiment_folder, 'folder created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing diabetes_training_from_tab_dataset/diabetes_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/diabetes_training.py\n",
    "# Import libraries\n",
    "import os\n",
    "import argparse\n",
    "from azureml.core import Run, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Get the script arguments (regularization rate and training dataset ID)\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01, help='regularization rate')\n",
    "parser.add_argument(\"--input-data\", type=str, dest='training_dataset_id', help='training dataset')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Set regularization hyperparameter (passed as an argument to the script)\n",
    "reg = args.reg_rate\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# Get the training dataset\n",
    "print(\"Loading Data...\")\n",
    "diabetes = run.input_datasets['training_data'].to_pandas_dataframe()\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "run.log('Regularization Rate',  np.float(reg))\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra note:\n",
    "\n",
    "#### Use a script argument for a tabular dataset\n",
    "\n",
    "You can pass a tabular dataset as a script argument. When you take this approach, the argument received by the script is the unique ID for the dataset in your workspace. In the script, you can then get the workspace from the run context and use it to retrieve the dataset by it's ID.\n",
    "\n",
    "ScriptRunConfig:\n",
    "\n",
    "```\n",
    "env = Environment('my_env')\n",
    "packages = CondaDependencies.create(conda_packages=['pip'],\n",
    "                                    pip_packages=['azureml-defaults',\n",
    "                                                  'azureml-dataprep[pandas]'])\n",
    "env.python.conda_dependencies = packages\n",
    "\n",
    "script_config = ScriptRunConfig(source_directory='my_dir',\n",
    "                                script='script.py',\n",
    "                                arguments=['--ds', tab_ds],\n",
    "                                environment=env)\n",
    "```\n",
    "\n",
    "Script:\n",
    "\n",
    "```\n",
    "from azureml.core import Run, Dataset\n",
    "\n",
    "parser.add_argument('--ds', type=str, dest='dataset_id')\n",
    "args = parser.parse_args()\n",
    "\n",
    "run = Run.get_context()\n",
    "ws = run.experiment.workspace\n",
    "dataset = Dataset.get_by_id(ws, id=args.dataset_id)\n",
    "data = dataset.to_pandas_dataframe()\n",
    "```\n",
    "\n",
    "#### Use a named input for a tabular dataset\n",
    "\n",
    "Alternatively, you can pass a tabular dataset as a named input. In this approach, you use the as_named_input method of the dataset to specify a name for the dataset. Then in the script, you can retrieve the dataset by name from the run context's input_datasets collection without needing to retrieve it from the workspace. Note that if you use this approach, you still need to include a script argument for the dataset, even though you don’t actually use it to retrieve the dataset.\n",
    "\n",
    "ScriptRunConfig:\n",
    "\n",
    "```\n",
    "env = Environment('my_env')\n",
    "packages = CondaDependencies.create(conda_packages=['pip'],\n",
    "                                    pip_packages=['azureml-defaults',\n",
    "                                                  'azureml-dataprep[pandas]'])\n",
    "env.python.conda_dependencies = packages\n",
    "\n",
    "script_config = ScriptRunConfig(source_directory='my_dir',\n",
    "                                script='script.py',\n",
    "                                arguments=['--ds', tab_ds.as_named_input('my_dataset')],\n",
    "                                environment=env)\n",
    "```\n",
    "\n",
    "Script:\n",
    "\n",
    "```\n",
    "from azureml.core import Run\n",
    "\n",
    "parser.add_argument('--ds', type=str, dest='ds_id')\n",
    "args = parser.parse_args()\n",
    "\n",
    "run = Run.get_context()\n",
    "dataset = run.input_datasets['my_dataset']\n",
    "data = dataset.to_pandas_dataframe()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: In the script, the dataset is passed as a parameter (or argument). In the case of a tabular dataset, this argument will contain the ID of the registered dataset; so you could write code in the script to get the experiment's workspace from the run context, and then get the dataset using its ID; like this:\n",
    ">\n",
    "> ```\n",
    "> run = Run.get_context()\n",
    "> ws = run.experiment.workspace\n",
    "> dataset = Dataset.get_by_id(ws, id=args.training_dataset_id)\n",
    "> diabetes = dataset.to_pandas_dataframe()\n",
    "> ```\n",
    ">\n",
    "> However, Azure Machine Learning runs automatically identify arguments that reference named datasets and add them to the run's **input_datasets** collection, so you can also retrieve the dataset from this collection by specifying its \"friendly name\" (which as you'll see shortly, is specified in the argument definition in the script run configuration for the experiment). This is the approach taken in the script above.\n",
    "\n",
    "Now you can run a script as an experiment, defining an argument for the training dataset, which is read by the script.\n",
    "\n",
    "> **Note**: The **Dataset** class depends on some components in the **azureml-dataprep** package, which includes optional support for **pandas** that is used by the **to_pandas_dataframe()** method. So you need to include this package in the environment where the training experiment will be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0946cf53ad14bbe99f65e9faab50b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/mslearn-train-diabetes/runs/mslearn-train-diabetes_1616615980_192b91d6?wsid=/subscriptions/cdb9c206-0977-4fc2-9190-23ed6c7c7063/resourcegroups/stanbic/workspaces/azure_ds_challenge\", \"run_id\": \"mslearn-train-diabetes_1616615980_192b91d6\", \"run_properties\": {\"run_id\": \"mslearn-train-diabetes_1616615980_192b91d6\", \"created_utc\": \"2021-03-24T19:59:40.634014Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"local\", \"ContentSnapshotId\": \"91551c3d-dad0-4499-83c4-a0293b5f2edc\", \"azureml.git.repository_uri\": \"https://github.com/MicrosoftLearning/mslearn-dp100\", \"mlflow.source.git.repoURL\": \"https://github.com/MicrosoftLearning/mslearn-dp100\", \"azureml.git.branch\": \"main\", \"mlflow.source.git.branch\": \"main\", \"azureml.git.commit\": \"f239fd89deb74b8808e79f452dab1b737a3c3070\", \"mlflow.source.git.commit\": \"f239fd89deb74b8808e79f452dab1b737a3c3070\", \"azureml.git.dirty\": \"True\"}, \"tags\": {}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2021-03-24T20:01:42.85012Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/60_control_log.txt\": \"https://azuredschallen0050415378.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1616615980_192b91d6/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=UNnxZCHLjhUiyZt%2Fbt0F0AiFm182meYsA%2FzM69GxiHI%3D&st=2021-03-24T19%3A51%3A44Z&se=2021-03-25T04%3A01%3A44Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://azuredschallen0050415378.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1616615980_192b91d6/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=MKj%2BB5aIOCSVgBjNWComYDXVecpl08E%2F57ji0NHJtwU%3D&st=2021-03-24T19%3A51%3A44Z&se=2021-03-25T04%3A01%3A44Z&sp=r\", \"logs/azureml/28168_azureml.log\": \"https://azuredschallen0050415378.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1616615980_192b91d6/logs/azureml/28168_azureml.log?sv=2019-02-02&sr=b&sig=%2FNNl9BDswK%2FMQqDjGHoKpsunq2bwZnW3kxl5i1W3yQQ%3D&st=2021-03-24T19%3A51%3A36Z&se=2021-03-25T04%3A01%3A36Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess.log\": \"https://azuredschallen0050415378.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1616615980_192b91d6/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=s%2BsqjBhgwsewzxep43bletaZFtQnHQC5yHrPwazEJxs%3D&st=2021-03-24T19%3A51%3A36Z&se=2021-03-25T04%3A01%3A36Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\": \"https://azuredschallen0050415378.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1616615980_192b91d6/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=KAJVruSV1Pz6farWfLoCBVMUOMgaiOr6tjk4cXBJ94k%3D&st=2021-03-24T19%3A51%3A36Z&se=2021-03-25T04%3A01%3A36Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/dataprep/backgroundProcess.log\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\"], [\"azureml-logs/60_control_log.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"logs/azureml/28168_azureml.log\"]], \"run_duration\": \"0:02:02\", \"run_number\": \"3\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"Regularization Rate\", \"run_id\": \"mslearn-train-diabetes_1616615980_192b91d6\", \"categories\": [0], \"series\": [{\"data\": [0.1]}]}, {\"name\": \"Accuracy\", \"run_id\": \"mslearn-train-diabetes_1616615980_192b91d6\", \"categories\": [0], \"series\": [{\"data\": [0.7891111111111111]}]}, {\"name\": \"AUC\", \"run_id\": \"mslearn-train-diabetes_1616615980_192b91d6\", \"categories\": [0], \"series\": [{\"data\": [0.8568595320655352]}]}], \"run_logs\": \"2021-03-24 20:01:13,334|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'EnableMLflowTracking': True, 'snapshotProject': True}, track_folders: None, deny_list: None, directories_to_watch: ['logs', 'logs/azureml']\\n2021-03-24 20:01:13,334|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: none\\n2021-03-24 20:01:13,335|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Failed to import pyspark with error: No module named 'pyspark'\\n2021-03-24 20:01:13,335|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2021-03-24 20:01:13,726|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7f41e1551730> for run source azureml.scriptrun\\n2021-03-24 20:01:13,727|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-03-24 20:01:13,727|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-03-24 20:01:13,729|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-03-24 20:01:13,738|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2021-03-24 20:01:13,738|azureml.core.authentication|DEBUG|Time to expire 1814306.261794 seconds\\n2021-03-24 20:01:13,738|azureml._restclient.service_context|DEBUG|Created a static thread pool for ServiceContext class\\n2021-03-24 20:01:13,738|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:01:13,738|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:01:13,739|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:01:13,739|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:01:13,739|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:01:13,739|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:01:13,739|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:01:13,778|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-03-24 20:01:13,779|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-03-24 20:01:13,842|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-03-24 20:01:13,843|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'local', 'ContentSnapshotId': '91551c3d-dad0-4499-83c4-a0293b5f2edc', 'azureml.git.repository_uri': 'https://github.com/MicrosoftLearning/mslearn-dp100', 'mlflow.source.git.repoURL': 'https://github.com/MicrosoftLearning/mslearn-dp100', 'azureml.git.branch': 'main', 'mlflow.source.git.branch': 'main', 'azureml.git.commit': 'f239fd89deb74b8808e79f452dab1b737a3c3070', 'mlflow.source.git.commit': 'f239fd89deb74b8808e79f452dab1b737a3c3070', 'azureml.git.dirty': 'True'}\\n2021-03-24 20:01:13,843|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-03-24 20:01:13,843|azureml|WARNING|Could not import azureml.mlflow or azureml.contrib.mlflow mlflow APIs will not run against AzureML services.  Add azureml-mlflow as a conda dependency for the run if this behavior is desired\\n2021-03-24 20:01:13,843|azureml.WorkerPool|DEBUG|[START]\\n2021-03-24 20:01:13,843|azureml.SendRunKillSignal|DEBUG|[START]\\n2021-03-24 20:01:13,843|azureml.RunStatusContext|DEBUG|[START]\\n2021-03-24 20:01:13,843|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunContextManager.RunStatusContext|DEBUG|[START]\\n2021-03-24 20:01:13,843|azureml.MetricsClient|DEBUG|[START]\\n2021-03-24 20:01:13,843|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.MetricsClient|DEBUG|[START]\\n2021-03-24 20:01:13,843|azureml.ContentUploader|DEBUG|[START]\\n2021-03-24 20:01:13,844|azureml._history.utils.context_managers|DEBUG|starting file watcher\\n2021-03-24 20:01:13,844|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|[Start]\\n2021-03-24 20:01:13,844|azureml.TrackFolders|DEBUG|[START]\\n2021-03-24 20:01:13,845|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2021-03-24 20:01:13,845|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2021-03-24 20:01:13,845|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /tmp/azureml_runs/mslearn-train-diabetes_1616615980_192b91d6\\n2021-03-24 20:01:13,845|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2021-03-24 20:01:13,845|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /tmp/azureml_runs/mslearn-train-diabetes_1616615980_192b91d6\\n2021-03-24 20:01:13,852|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2021-03-24 20:01:13,852|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2021-03-24 20:01:14,018|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2021-03-24 20:01:14,047|azureml._history.utils.context_managers.FileWatcher|DEBUG|uploading data to container: azureml blob: ExperimentRun/dcid.mslearn-train-diabetes_1616615980_192b91d6/logs/azureml/28168_azureml.log path: /tmp/azureml_runs/mslearn-train-diabetes_1616615980_192b91d6/logs/azureml/28168_azureml.log\\n2021-03-24 20:01:14,048|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2021-03-24 20:01:14,048|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result|DEBUG|Using basic handler - no exception handling\\n2021-03-24 20:01:14,049|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 0_result to queue of approximate size: 0\\n2021-03-24 20:01:20,678|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-03-24 20:01:20,678|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-03-24 20:01:20,679|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-03-24 20:01:20,679|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:01:20,679|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:01:20,679|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:01:20,679|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:01:20,680|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:01:20,680|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:01:20,680|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:01:20,717|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-03-24 20:01:20,717|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-03-24 20:01:20,775|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-03-24 20:01:20,776|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'local', 'ContentSnapshotId': '91551c3d-dad0-4499-83c4-a0293b5f2edc', 'azureml.git.repository_uri': 'https://github.com/MicrosoftLearning/mslearn-dp100', 'mlflow.source.git.repoURL': 'https://github.com/MicrosoftLearning/mslearn-dp100', 'azureml.git.branch': 'main', 'mlflow.source.git.branch': 'main', 'azureml.git.commit': 'f239fd89deb74b8808e79f452dab1b737a3c3070', 'mlflow.source.git.commit': 'f239fd89deb74b8808e79f452dab1b737a3c3070', 'azureml.git.dirty': 'True'}\\n2021-03-24 20:01:20,777|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-03-24 20:01:20,942|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-03-24 20:01:20,943|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-03-24 20:01:20,943|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-03-24 20:01:20,943|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:01:20,943|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:01:20,944|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:01:20,944|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:01:20,944|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:01:20,944|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:01:20,944|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:01:24,049|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2021-03-24 20:01:24,054|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result|DEBUG|Using basic handler - no exception handling\\n2021-03-24 20:01:24,054|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 1_result to queue of approximate size: 1\\n2021-03-24 20:01:27,287|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-03-24 20:01:27,287|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2021-03-24 20:01:27,287|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-03-24 20:01:27,575|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6|INFO|complete is not setting status for submitted runs.\\n2021-03-24 20:01:27,575|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-03-24 20:01:27,575|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-03-24 20:01:27,575|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-03-24 20:01:27,575|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-03-24 20:01:27,575|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-03-24 20:01:27,575|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-03-24 20:01:27,575|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2021-03-24 20:01:27,576|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-03-24 20:01:27,576|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-03-24 20:01:27,576|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2021-03-24 20:01:27,576|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2021-03-24 20:01:27,576|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 3.\\n2021-03-24 20:01:27,576|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2021-03-24 20:01:27,576|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2021-03-24 20:01:27,576|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2021-03-24 20:01:27,576|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2021-03-24 20:01:27,576|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2021-03-24 20:01:27,576|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2021-03-24 20:01:27,576|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _log_batch_v2\\n2021-03-24 20:01:27,577|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 3 values.\\n2021-03-24 20:01:27,577|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2|DEBUG|Using basic handler - no exception handling\\n2021-03-24 20:01:27,577|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 0__log_batch_v2 to queue of approximate size: 0\\n2021-03-24 20:01:27,577|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[START]\\n2021-03-24 20:01:27,577|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling _post_run_metrics_log_failed_validations with url None\\n2021-03-24 20:01:27,754|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[STOP]\\n2021-03-24 20:01:27,827|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2021-03-24 20:01:27,827|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2021-03-24 20:01:27,827|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2021-03-24 20:01:27,827|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Waiting on task: 0__handle_batch.\\n1 tasks left. Current duration of flush 6.389617919921875e-05 seconds.\\n\\n2021-03-24 20:01:27,827|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2021-03-24 20:01:27,827|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-03-24 20:01:27,827|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-03-24 20:01:27,827|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [AsyncTask(0__log_batch_v2)].\\n2021-03-24 20:01:27,827|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[START]\\n2021-03-24 20:01:27,827|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|Awaiter is PostMetricsBatchV2\\n2021-03-24 20:01:27,827|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[STOP]\\n2021-03-24 20:01:27,827|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-03-24 20:01:27,827|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-03-24 20:01:27,827|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-03-24 20:01:27,828|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-03-24 20:01:27,828|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-03-24 20:01:27,886|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-03-24 20:01:32,888|azureml._restclient.clientbase|DEBUG|ClientBase: Calling update_status with url None\\n2021-03-24 20:01:32,950|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Uploading tracked directories: [], excluding []\\n2021-03-24 20:01:32,950|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling track for pyfs\\n2021-03-24 20:01:33,284|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2021-03-24 20:01:33,285|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /tmp/azureml_runs/mslearn-train-diabetes_1616615980_192b91d6\\n2021-03-24 20:01:33,285|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from /tmp/azureml_runs/mslearn-train-diabetes_1616615980_192b91d6 to /tmp/azureml_runs/mslearn-train-diabetes_1616615980_192b91d6\\n2021-03-24 20:01:33,285|azureml.history._tracking.PythonWorkingDirectory|INFO|Working dir is already updated /tmp/azureml_runs/mslearn-train-diabetes_1616615980_192b91d6\\n2021-03-24 20:01:33,285|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\n2021-03-24 20:01:33,285|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\n2021-03-24 20:01:33,285|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Uploading tracked directories: ['./outputs'], excluding ['azureml-logs/driver_log']\\n2021-03-24 20:01:33,285|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling track for pyfs\\n2021-03-24 20:01:33,285|azureml.history._tracking.PythonWorkingDirectory|DEBUG|./outputs exists as directory, uploading..\\n2021-03-24 20:01:33,285|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Found and adding path to upload: ./outputs/diabetes_model.pkl\\n2021-03-24 20:01:33,285|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Paths to upload is ['./outputs/diabetes_model.pkl'] in dir ./outputs\\n2021-03-24 20:01:33,285|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Overriding default timeout to 300\\n2021-03-24 20:01:33,285|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|[Start]\\n2021-03-24 20:01:33,285|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2021-03-24 20:01:33,285|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2021-03-24 20:01:33,425|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2021-03-24 20:01:33,425|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: perform_upload\\n2021-03-24 20:01:33,425|azureml._restclient.clientbase|DEBUG|ClientBase: Calling create_blob_from_stream with url None\\n2021-03-24 20:01:33,426|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload|DEBUG|Using basic handler - no exception handling\\n2021-03-24 20:01:33,426|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Adding task 0_perform_upload to queue of approximate size: 0\\n2021-03-24 20:01:33,426|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|[Stop] - waiting default timeout\\n2021-03-24 20:01:33,426|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|[START]\\n2021-03-24 20:01:33,426|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|Overriding default flush timeout from None to 300\\n2021-03-24 20:01:33,427|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|Waiting 300 seconds on tasks: [AsyncTask(0_perform_upload)].\\n2021-03-24 20:01:33,475|azureml._file_utils.upload|DEBUG|Uploaded blob ExperimentRun/dcid.mslearn-train-diabetes_1616615980_192b91d6/outputs/diabetes_model.pkl with size 964, file size 964.\\n2021-03-24 20:01:33,677|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload.WaitingTask|DEBUG|[START]\\n2021-03-24 20:01:33,677|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload.WaitingTask|DEBUG|Awaiter is upload_files\\n2021-03-24 20:01:33,677|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload.WaitingTask|DEBUG|[STOP]\\n2021-03-24 20:01:33,677|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Waiting on task: 0_perform_upload.\\n1 tasks left. Current duration of flush 6.890296936035156e-05 seconds.\\n\\n2021-03-24 20:01:33,677|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|[STOP]\\n2021-03-24 20:01:33,677|azureml.TrackFolders|DEBUG|[STOP]\\n2021-03-24 20:01:33,677|azureml._history.utils.context_managers|DEBUG|exiting ContentUploader, waiting for file_watcher to finish upload...\\n2021-03-24 20:01:33,677|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher called finish, setting event\\n2021-03-24 20:01:33,678|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher received exit event, getting current_stat\\n2021-03-24 20:01:33,678|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2021-03-24 20:01:33,678|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2021-03-24 20:01:33,887|azureml._SubmittedRun#mslearn-train-diabetes_1616615980_192b91d6.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2021-03-24 20:01:33,915|azureml._history.utils.context_managers.FileWatcher|DEBUG|uploading data to container: azureml blob: ExperimentRun/dcid.mslearn-train-diabetes_1616615980_192b91d6/logs/azureml/dataprep/backgroundProcess_Telemetry.log path: /tmp/azureml_runs/mslearn-train-diabetes_1616615980_192b91d6/logs/azureml/dataprep/backgroundProcess_Telemetry.log\\n2021-03-24 20:01:33,951|azureml._history.utils.context_managers.FileWatcher|DEBUG|uploading data to container: azureml blob: ExperimentRun/dcid.mslearn-train-diabetes_1616615980_192b91d6/logs/azureml/dataprep/backgroundProcess.log path: /tmp/azureml_runs/mslearn-train-diabetes_1616615980_192b91d6/logs/azureml/dataprep/backgroundProcess.log\\n2021-03-24 20:01:33,952|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2021-03-24 20:01:33,955|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result|DEBUG|Using basic handler - no exception handling\\n2021-03-24 20:01:33,955|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 2_result to queue of approximate size: 2\\n2021-03-24 20:01:33,955|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2021-03-24 20:01:33,958|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result|DEBUG|Using basic handler - no exception handling\\n2021-03-24 20:01:33,958|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 3_result to queue of approximate size: 3\\n2021-03-24 20:01:33,958|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2021-03-24 20:01:33,960|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result|DEBUG|Using basic handler - no exception handling\\n2021-03-24 20:01:33,960|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 4_result to queue of approximate size: 4\\n2021-03-24 20:01:33,960|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher retrieved current_stat, will upload to current_stat\\n2021-03-24 20:01:33,961|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,961|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,961|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,961|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,962|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,962|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,962|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,962|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,962|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,963|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,963|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,963|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,963|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,964|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,964|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,964|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,965|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2021-03-24 20:01:33,969|azureml._history.utils.context_managers.FileWatcher.UploadQueue.5_result|DEBUG|Using basic handler - no exception handling\\n2021-03-24 20:01:33,969|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 5_result to queue of approximate size: 5\\n2021-03-24 20:01:33,969|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,969|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,969|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,970|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,970|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,970|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,970|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,970|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,971|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,971|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,971|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,971|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,972|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,972|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,972|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,972|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,972|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,973|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,973|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,973|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,973|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,973|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,974|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,974|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,974|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,974|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,975|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,975|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,975|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,975|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,975|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,976|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,976|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,976|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,976|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,977|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,977|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,977|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,977|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:01:33,978|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2021-03-24 20:01:33,982|azureml._history.utils.context_managers.FileWatcher.UploadQueue.6_result|DEBUG|Using basic handler - no exception handling\\n2021-03-24 20:01:33,982|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 6_result to queue of approximate size: 6\\n2021-03-24 20:01:33,982|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher finished uploading to current_stat, finishing task queue\\n2021-03-24 20:01:33,982|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|[Stop] - waiting default timeout\\n2021-03-24 20:01:33,982|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|[START]\\n2021-03-24 20:01:33,982|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|Overriding default flush timeout from None to 120\\n2021-03-24 20:01:33,982|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0_result), AsyncTask(1_result), AsyncTask(2_result), AsyncTask(3_result), AsyncTask(4_result), AsyncTask(5_result), AsyncTask(6_result)].\\n2021-03-24 20:01:33,982|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|[START]\\n2021-03-24 20:01:33,982|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2021-03-24 20:01:33,982|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|[STOP]\\n2021-03-24 20:01:33,982|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|[START]\\n2021-03-24 20:01:33,983|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2021-03-24 20:01:33,983|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|[STOP]\\n2021-03-24 20:01:33,983|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|[START]\\n2021-03-24 20:01:33,983|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2021-03-24 20:01:33,983|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|[STOP]\\n2021-03-24 20:01:33,983|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result.WaitingTask|DEBUG|[START]\\n2021-03-24 20:01:33,983|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2021-03-24 20:01:33,983|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result.WaitingTask|DEBUG|[STOP]\\n2021-03-24 20:01:33,983|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result.WaitingTask|DEBUG|[START]\\n2021-03-24 20:01:33,983|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2021-03-24 20:01:33,983|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result.WaitingTask|DEBUG|[STOP]\\n2021-03-24 20:01:33,983|azureml._history.utils.context_managers.FileWatcher.UploadQueue.5_result.WaitingTask|DEBUG|[START]\\n2021-03-24 20:01:33,983|azureml._history.utils.context_managers.FileWatcher.UploadQueue.5_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2021-03-24 20:01:33,983|azureml._history.utils.context_managers.FileWatcher.UploadQueue.5_result.WaitingTask|DEBUG|[STOP]\\n2021-03-24 20:01:34,234|azureml._history.utils.context_managers.FileWatcher.UploadQueue.6_result.WaitingTask|DEBUG|[START]\\n2021-03-24 20:01:34,234|azureml._history.utils.context_managers.FileWatcher.UploadQueue.6_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2021-03-24 20:01:34,234|azureml._history.utils.context_managers.FileWatcher.UploadQueue.6_result.WaitingTask|DEBUG|[STOP]\\n2021-03-24 20:01:34,234|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Waiting on task: 6_result.\\n1 tasks left. Current duration of flush 0.0010371208190917969 seconds.\\n\\n2021-03-24 20:01:34,234|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|[STOP]\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.22.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'mslearn-train-diabetes_1616615980_192b91d6',\n",
       " 'target': 'local',\n",
       " 'status': 'Finalizing',\n",
       " 'startTimeUtc': '2021-03-24T20:01:12.453392Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  'ContentSnapshotId': '91551c3d-dad0-4499-83c4-a0293b5f2edc',\n",
       "  'azureml.git.repository_uri': 'https://github.com/MicrosoftLearning/mslearn-dp100',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/MicrosoftLearning/mslearn-dp100',\n",
       "  'azureml.git.branch': 'main',\n",
       "  'mlflow.source.git.branch': 'main',\n",
       "  'azureml.git.commit': 'f239fd89deb74b8808e79f452dab1b737a3c3070',\n",
       "  'mlflow.source.git.commit': 'f239fd89deb74b8808e79f452dab1b737a3c3070',\n",
       "  'azureml.git.dirty': 'True'},\n",
       " 'inputDatasets': [{'dataset': {'id': 'ff8a00da-9ff5-40f5-a399-65a5a6af758c'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'training_data', 'mechanism': 'Direct'}}],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'diabetes_training.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--regularization',\n",
       "   '0.1',\n",
       "   '--input-data',\n",
       "   'DatasetConsumptionConfig:training_data'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {},\n",
       "  'data': {'training_data': {'dataLocation': {'dataset': {'id': 'ff8a00da-9ff5-40f5-a399-65a5a6af758c',\n",
       "      'name': 'diabetes dataset',\n",
       "      'version': '1'},\n",
       "     'dataPath': None},\n",
       "    'mechanism': 'Direct',\n",
       "    'environmentVariableName': 'training_data',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False}},\n",
       "  'outputData': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 1,\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'sklearn-env',\n",
       "   'version': 'Autosave_2021-03-24T19:59:40Z_39254d5c',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults~=1.22.0', 'azureml-dataprep[pandas]']},\n",
       "      'scikit-learn',\n",
       "      'pip'],\n",
       "     'name': 'azureml_2f7b943ce285cfcb7487460b5c8d4fe6'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210104.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': None,\n",
       "   'imageVersion': None,\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None,\n",
       "   'virtualClusterArmId': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': False,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {}},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://azuredschallen0050415378.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1616615980_192b91d6/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=Xhcfi8IYaK5k0cENdqG5tya628kILmSRpmf99kD96h8%3D&st=2021-03-24T19%3A51%3A36Z&se=2021-03-25T04%3A01%3A36Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://azuredschallen0050415378.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1616615980_192b91d6/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=sbeozY6Ux07UDsgDBvZIT4Lq8h9NGDZ1rZIiD5u2iiY%3D&st=2021-03-24T19%3A51%3A36Z&se=2021-03-25T04%3A01%3A36Z&sp=r',\n",
       "  'logs/azureml/28168_azureml.log': 'https://azuredschallen0050415378.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1616615980_192b91d6/logs/azureml/28168_azureml.log?sv=2019-02-02&sr=b&sig=%2FNNl9BDswK%2FMQqDjGHoKpsunq2bwZnW3kxl5i1W3yQQ%3D&st=2021-03-24T19%3A51%3A36Z&se=2021-03-25T04%3A01%3A36Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess.log': 'https://azuredschallen0050415378.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1616615980_192b91d6/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=s%2BsqjBhgwsewzxep43bletaZFtQnHQC5yHrPwazEJxs%3D&st=2021-03-24T19%3A51%3A36Z&se=2021-03-25T04%3A01%3A36Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://azuredschallen0050415378.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1616615980_192b91d6/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=KAJVruSV1Pz6farWfLoCBVMUOMgaiOr6tjk4cXBJ94k%3D&st=2021-03-24T19%3A51%3A36Z&se=2021-03-25T04%3A01%3A36Z&sp=r'},\n",
       " 'submittedBy': 'Chidi Ndego'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "\n",
    "# Create a Python environment for the experiment\n",
    "sklearn_env = Environment(\"sklearn-env\")\n",
    "\n",
    "# Ensure the required packages are installed (we need scikit-learn, Azure ML defaults, and Azure ML dataprep)\n",
    "packages = CondaDependencies.create(conda_packages=['scikit-learn','pip'],\n",
    "                                    pip_packages=['azureml-defaults','azureml-dataprep[pandas]'])\n",
    "sklearn_env.python.conda_dependencies = packages\n",
    "\n",
    "# Get the training dataset\n",
    "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
    "\n",
    "# Create a script config\n",
    "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
    "                              script='diabetes_training.py',\n",
    "                              arguments = ['--regularization', 0.1, # Regularizaton rate parameter\n",
    "                                           '--input-data', diabetes_ds.as_named_input('training_data')], # Reference to dataset\n",
    "                              environment=sklearn_env) \n",
    "\n",
    "# submit the experiment\n",
    "experiment_name = 'mslearn-train-diabetes'\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)\n",
    "run = experiment.submit(config=script_config)\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** The **--input-data** argument passes the dataset as a *named input* that includes a *friendly name* for the dataset, which is used by the script to read it from the **input_datasets** collection in the experiment run. The string value in the **--input-data** argument is actually the registered dataset's ID.  As an alternative approach, you could simply pass `diabetes_ds.id`, in which case the script can access the dataset ID from the script arguments and use it to get the dataset from the workspace, but not from the **input_datasets** collection.\n",
    "\n",
    "The first time the experiment is run, it may take some time to set up the Python environment - subsequent runs will be quicker.\n",
    "\n",
    "When the experiment has completed, in the widget, view the **azureml-logs/70_driver_log.txt** output log and the metrics generated by the run.\n",
    "\n",
    "### Register the trained model\n",
    "\n",
    "As with any training experiment, you can retrieve the trained model and register it in your Azure Machine Learning workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_model version: 3\n",
      "\t Training context : Tabular dataset\n",
      "\t AUC : 0.8568595320655352\n",
      "\t Accuracy : 0.7891111111111111\n",
      "\n",
      "\n",
      "diabetes_model version: 2\n",
      "\t Training context : Parameterized script\n",
      "\t AUC : 0.8484357430717946\n",
      "\t Accuracy : 0.774\n",
      "\n",
      "\n",
      "diabetes_model version: 1\n",
      "\t Training context : Script\n",
      "\t AUC : 0.8483203144435048\n",
      "\t Accuracy : 0.774\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
    "                   tags={'Training context':'Tabular dataset'}, properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
    "\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model from a file dataset\n",
    "\n",
    "You've seen how to train a model using training data in a *tabular* dataset; but what about a *file* dataset?\n",
    "\n",
    "When you're using a file dataset, the dataset argument passed to the script represents a mount point containing file paths. How you read the data from these files depends on the kind of data in the files and what you want to do with it. In the case of the diabetes CSV files, you can use the Python **glob** module to create a list of files in the virtual mount point defined by the dataset, and read them all into Pandas dataframes that are concatenated into a single dataframe.\n",
    "\n",
    "Run the following two code cells to create:\n",
    "\n",
    "1. A folder named **diabetes_training_from_file_dataset**\n",
    "2. A script that trains a classification model by using a file dataset that is passed to is as an *input*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_training_from_file_dataset folder created\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "experiment_folder = 'diabetes_training_from_file_dataset'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "print(experiment_folder, 'folder created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing diabetes_training_from_file_dataset/diabetes_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/diabetes_training.py\n",
    "# Import libraries\n",
    "import os\n",
    "import argparse\n",
    "from azureml.core import Dataset, Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import glob\n",
    "\n",
    "# Get script arguments (rgularization rate and file dataset mount point)\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01, help='regularization rate')\n",
    "parser.add_argument('--input-data', type=str, dest='dataset_folder', help='data mount point')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Set regularization hyperparameter (passed as an argument to the script)\n",
    "reg = args.reg_rate\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "data_path = run.input_datasets['training_files'] # Get the training data path from the input\n",
    "# (You could also just use args.data_folder if you don't want to rely on a hard-coded friendly name)\n",
    "\n",
    "# Read the files\n",
    "all_files = glob.glob(data_path + \"/*.csv\")\n",
    "diabetes = pd.concat((pd.read_csv(f) for f in all_files), sort=False)\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "run.log('Regularization Rate',  np.float(reg))\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as with tabular datasets, you can retrieve a file dataset from the **input_datasets** collection by using its friendly name. You can also retrieve it from the script argument, which in the case of a file dataset contains a mount path to the files (rather than the dataset ID passed for a tabular dataset).\n",
    "\n",
    "Next we need to change the way we pass the dataset to the script - it needs to define a path from which the script can read the files. You can use either the **as_download** or **as_mount** method to do this. Using **as_download** causes the files in the file dataset to be downloaded to a temporary location on the compute where the script is being run, while **as_mount** creates a mount point from which the files can be streamed directly from the datasetore.\n",
    "\n",
    "You can combine the access method with the **as_named_input** method to include the dataset in the **input_datasets** collection in the experiment run (if you omit this, for example by setting the argument to `diabetes_ds.as_mount()`, the script will be able to access the dataset mount point from the script arguments, but not from the **input_datasets** collection)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra note:\n",
    "\n",
    "#### Use a script argument for a file dataset\n",
    "\n",
    "You can pass a file dataset as a script argument. Unlike with a tabular dataset, you must specify a mode for the file dataset argument, which can be as_download or as_mount. This provides an access point that the script can use to read the files in the dataset. In most cases, you should use as_download, which copies the files to a temporary location on the compute where the script is being run. However, if you are working with a large amount of data for which there may not be enough storage space on the experiment compute, use as_mount to stream the files directly from their source.\n",
    "\n",
    "ScriptRunConfig:\n",
    "\n",
    "```\n",
    "env = Environment('my_env')\n",
    "packages = CondaDependencies.create(conda_packages=['pip'],\n",
    "                                    pip_packages=['azureml-defaults',\n",
    "                                                  'azureml-dataprep[pandas]'])\n",
    "env.python.conda_dependencies = packages\n",
    "\n",
    "script_config = ScriptRunConfig(source_directory='my_dir',\n",
    "                                script='script.py',\n",
    "                                arguments=['--ds', file_ds.as_download()],\n",
    "                                environment=env)\n",
    "```\n",
    "\n",
    "Script:\n",
    "\n",
    "```\n",
    "from azureml.core import Run\n",
    "import glob\n",
    "\n",
    "parser.add_argument('--ds', type=str, dest='ds_ref')\n",
    "args = parser.parse_args()\n",
    "run = Run.get_context()\n",
    "\n",
    "imgs = glob.glob(ds_ref + \"/*.jpg\")\n",
    "```\n",
    "\n",
    "#### Use a named input for a file dataset\n",
    "\n",
    "You can also pass a file dataset as a named input. In this approach, you use the as_named_input method of the dataset to specify a name before specifying the access mode. Then in the script, you can retrieve the dataset by name from the run context's input_datasets collection and read the files from there. As with tabular datasets, if you use a named input, you still need to include a script argument for the dataset, even though you don’t actually use it to retrieve the dataset.\n",
    "\n",
    "ScriptRunConfig:\n",
    "\n",
    "```\n",
    "env = Environment('my_env')\n",
    "packages = CondaDependencies.create(conda_packages=['pip'],\n",
    "                                    pip_packages=['azureml-defaults',\n",
    "                                                  'azureml-dataprep[pandas]'])\n",
    "env.python.conda_dependencies = packages\n",
    "\n",
    "script_config = ScriptRunConfig(source_directory='my_dir',\n",
    "                                script='script.py',\n",
    "                                arguments=['--ds', file_ds.as_named_input('my_ds').as_download()],\n",
    "                                environment=env)\n",
    "```\n",
    "\n",
    "Script:\n",
    "\n",
    "```\n",
    "from azureml.core import Run\n",
    "import glob\n",
    "\n",
    "parser.add_argument('--ds', type=str, dest='ds_ref')\n",
    "args = parser.parse_args()\n",
    "run = Run.get_context()\n",
    "\n",
    "dataset = run.input_datasets['my_ds']\n",
    "imgs= glob.glob(dataset + \"/*.jpg\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d72ace95f5ab45c8af04058ad68b82ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/mslearn-train-diabetes/runs/mslearn-train-diabetes_1616616163_599b8229?wsid=/subscriptions/cdb9c206-0977-4fc2-9190-23ed6c7c7063/resourcegroups/stanbic/workspaces/azure_ds_challenge\", \"run_id\": \"mslearn-train-diabetes_1616616163_599b8229\", \"run_properties\": {\"run_id\": \"mslearn-train-diabetes_1616616163_599b8229\", \"created_utc\": \"2021-03-24T20:02:44.535626Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"local\", \"ContentSnapshotId\": \"90de8ea8-c400-4df8-bd81-64928319ddc8\", \"azureml.git.repository_uri\": \"https://github.com/MicrosoftLearning/mslearn-dp100\", \"mlflow.source.git.repoURL\": \"https://github.com/MicrosoftLearning/mslearn-dp100\", \"azureml.git.branch\": \"main\", \"mlflow.source.git.branch\": \"main\", \"azureml.git.commit\": \"f239fd89deb74b8808e79f452dab1b737a3c3070\", \"mlflow.source.git.commit\": \"f239fd89deb74b8808e79f452dab1b737a3c3070\", \"azureml.git.dirty\": \"True\"}, \"tags\": {}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2021-03-24T20:03:17.094223Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/60_control_log.txt\": \"https://azuredschallen0050415378.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1616616163_599b8229/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=Yxz4Aakmqxm9jVtnhq14JazJXSQzgFiF6Eo%2F97YKn%2F0%3D&st=2021-03-24T19%3A53%3A22Z&se=2021-03-25T04%3A03%3A22Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://azuredschallen0050415378.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1616616163_599b8229/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=xL5o%2BqJspRF1lhjTK5r9QPY1CUabAork1baS17V8iHU%3D&st=2021-03-24T19%3A53%3A22Z&se=2021-03-25T04%3A03%3A22Z&sp=r\", \"logs/azureml/30422_azureml.log\": \"https://azuredschallen0050415378.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1616616163_599b8229/logs/azureml/30422_azureml.log?sv=2019-02-02&sr=b&sig=ZiRHcy9wtiIzTUf7dY9Iyu7gBe3e%2Fzq7TvXA5e5ytFA%3D&st=2021-03-24T19%3A52%3A57Z&se=2021-03-25T04%3A02%3A57Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess.log\": \"https://azuredschallen0050415378.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1616616163_599b8229/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=4RITgtgQoilIzWTSYoM5kEI8d4dkDHy%2F%2FidCnH7nUjU%3D&st=2021-03-24T19%3A52%3A57Z&se=2021-03-25T04%3A02%3A57Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\": \"https://azuredschallen0050415378.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1616616163_599b8229/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=wPWYmu6pLWD8JkMm5D5jFmAHikI0YAQnDaY5myBMoB4%3D&st=2021-03-24T19%3A52%3A57Z&se=2021-03-25T04%3A02%3A57Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/dataprep/backgroundProcess.log\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\"], [\"azureml-logs/60_control_log.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"logs/azureml/30422_azureml.log\"]], \"run_duration\": \"0:00:32\", \"run_number\": \"4\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"Regularization Rate\", \"run_id\": \"mslearn-train-diabetes_1616616163_599b8229\", \"categories\": [0], \"series\": [{\"data\": [0.1]}]}, {\"name\": \"Accuracy\", \"run_id\": \"mslearn-train-diabetes_1616616163_599b8229\", \"categories\": [0], \"series\": [{\"data\": [0.7891111111111111]}]}, {\"name\": \"AUC\", \"run_id\": \"mslearn-train-diabetes_1616616163_599b8229\", \"categories\": [0], \"series\": [{\"data\": [0.8568517900798176]}]}], \"run_logs\": \"2021-03-24 20:02:55,877|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'EnableMLflowTracking': True, 'snapshotProject': True}, track_folders: None, deny_list: None, directories_to_watch: ['logs', 'logs/azureml']\\n2021-03-24 20:02:55,878|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-03-24 20:02:55,878|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-03-24 20:02:55,878|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-03-24 20:02:55,878|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:02:55,879|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:02:55,879|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:02:55,879|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:02:55,879|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:02:55,879|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:02:55,879|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:02:55,914|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-03-24 20:02:55,914|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-03-24 20:02:55,983|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-03-24 20:02:55,984|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'local', 'ContentSnapshotId': '90de8ea8-c400-4df8-bd81-64928319ddc8', 'azureml.git.repository_uri': 'https://github.com/MicrosoftLearning/mslearn-dp100', 'mlflow.source.git.repoURL': 'https://github.com/MicrosoftLearning/mslearn-dp100', 'azureml.git.branch': 'main', 'mlflow.source.git.branch': 'main', 'azureml.git.commit': 'f239fd89deb74b8808e79f452dab1b737a3c3070', 'mlflow.source.git.commit': 'f239fd89deb74b8808e79f452dab1b737a3c3070', 'azureml.git.dirty': 'True'}\\n2021-03-24 20:02:55,984|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-03-24 20:02:55,985|azureml|WARNING|Could not import azureml.mlflow or azureml.contrib.mlflow mlflow APIs will not run against AzureML services.  Add azureml-mlflow as a conda dependency for the run if this behavior is desired\\n2021-03-24 20:02:55,985|azureml.WorkerPool|DEBUG|[START]\\n2021-03-24 20:02:55,985|azureml.SendRunKillSignal|DEBUG|[START]\\n2021-03-24 20:02:55,985|azureml.RunStatusContext|DEBUG|[START]\\n2021-03-24 20:02:55,985|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunContextManager.RunStatusContext|DEBUG|[START]\\n2021-03-24 20:02:55,985|azureml.MetricsClient|DEBUG|[START]\\n2021-03-24 20:02:55,985|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.MetricsClient|DEBUG|[START]\\n2021-03-24 20:02:55,985|azureml.ContentUploader|DEBUG|[START]\\n2021-03-24 20:02:55,986|azureml._history.utils.context_managers|DEBUG|starting file watcher\\n2021-03-24 20:02:55,986|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|[Start]\\n2021-03-24 20:02:55,986|azureml.TrackFolders|DEBUG|[START]\\n2021-03-24 20:02:55,986|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2021-03-24 20:02:55,986|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2021-03-24 20:02:55,986|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /tmp/azureml_runs/mslearn-train-diabetes_1616616163_599b8229\\n2021-03-24 20:02:55,986|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2021-03-24 20:02:55,986|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /tmp/azureml_runs/mslearn-train-diabetes_1616616163_599b8229\\n2021-03-24 20:02:56,000|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2021-03-24 20:02:56,000|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2021-03-24 20:02:56,230|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2021-03-24 20:02:56,281|azureml._history.utils.context_managers.FileWatcher|DEBUG|uploading data to container: azureml blob: ExperimentRun/dcid.mslearn-train-diabetes_1616616163_599b8229/logs/azureml/30422_azureml.log path: /tmp/azureml_runs/mslearn-train-diabetes_1616616163_599b8229/logs/azureml/30422_azureml.log\\n2021-03-24 20:02:56,369|azureml._history.utils.context_managers.FileWatcher|DEBUG|uploading data to container: azureml blob: ExperimentRun/dcid.mslearn-train-diabetes_1616616163_599b8229/logs/azureml/dataprep/backgroundProcess_Telemetry.log path: /tmp/azureml_runs/mslearn-train-diabetes_1616616163_599b8229/logs/azureml/dataprep/backgroundProcess_Telemetry.log\\n2021-03-24 20:02:56,409|azureml._history.utils.context_managers.FileWatcher|DEBUG|uploading data to container: azureml blob: ExperimentRun/dcid.mslearn-train-diabetes_1616616163_599b8229/logs/azureml/dataprep/backgroundProcess.log path: /tmp/azureml_runs/mslearn-train-diabetes_1616616163_599b8229/logs/azureml/dataprep/backgroundProcess.log\\n2021-03-24 20:02:56,409|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2021-03-24 20:02:56,425|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result|DEBUG|Using basic handler - no exception handling\\n2021-03-24 20:02:56,425|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 0_result to queue of approximate size: 0\\n2021-03-24 20:02:56,426|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2021-03-24 20:02:56,442|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result|DEBUG|Using basic handler - no exception handling\\n2021-03-24 20:02:56,442|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 1_result to queue of approximate size: 1\\n2021-03-24 20:02:56,442|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2021-03-24 20:02:56,456|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result|DEBUG|Using basic handler - no exception handling\\n2021-03-24 20:02:56,456|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 2_result to queue of approximate size: 2\\n2021-03-24 20:02:56,811|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-03-24 20:02:56,811|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-03-24 20:02:56,811|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-03-24 20:02:56,811|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:02:56,811|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:02:56,812|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:02:56,812|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:02:56,812|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:02:56,812|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:02:56,812|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus2.experiments.azureml.net.\\n2021-03-24 20:02:56,907|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-03-24 20:02:56,907|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2021-03-24 20:02:56,907|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-03-24 20:02:57,065|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229|INFO|complete is not setting status for submitted runs.\\n2021-03-24 20:02:57,065|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-03-24 20:02:57,065|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-03-24 20:02:57,065|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-03-24 20:02:57,066|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-03-24 20:02:57,066|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-03-24 20:02:57,066|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-03-24 20:02:57,066|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2021-03-24 20:02:57,066|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-03-24 20:02:57,066|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-03-24 20:02:57,066|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2021-03-24 20:02:57,066|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2021-03-24 20:02:57,066|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 3.\\n2021-03-24 20:02:57,066|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2021-03-24 20:02:57,067|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2021-03-24 20:02:57,067|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2021-03-24 20:02:57,067|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2021-03-24 20:02:57,067|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2021-03-24 20:02:57,067|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2021-03-24 20:02:57,067|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _log_batch_v2\\n2021-03-24 20:02:57,067|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 3 values.\\n2021-03-24 20:02:57,067|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2|DEBUG|Using basic handler - no exception handling\\n2021-03-24 20:02:57,067|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 0__log_batch_v2 to queue of approximate size: 0\\n2021-03-24 20:02:57,067|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[START]\\n2021-03-24 20:02:57,067|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling _post_run_metrics_log_failed_validations with url None\\n2021-03-24 20:02:57,252|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[STOP]\\n2021-03-24 20:02:57,317|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2021-03-24 20:02:57,317|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2021-03-24 20:02:57,318|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2021-03-24 20:02:57,318|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Waiting on task: 0__handle_batch.\\n1 tasks left. Current duration of flush 6.0558319091796875e-05 seconds.\\n\\n2021-03-24 20:02:57,318|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2021-03-24 20:02:57,318|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-03-24 20:02:57,318|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-03-24 20:02:57,318|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [AsyncTask(0__log_batch_v2)].\\n2021-03-24 20:02:57,318|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[START]\\n2021-03-24 20:02:57,318|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|Awaiter is PostMetricsBatchV2\\n2021-03-24 20:02:57,318|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[STOP]\\n2021-03-24 20:02:57,318|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-03-24 20:02:57,318|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-03-24 20:02:57,318|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-03-24 20:02:57,318|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-03-24 20:02:57,318|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-03-24 20:02:57,385|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-03-24 20:03:02,388|azureml._restclient.clientbase|DEBUG|ClientBase: Calling update_status with url None\\n2021-03-24 20:03:02,440|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Uploading tracked directories: [], excluding []\\n2021-03-24 20:03:02,440|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling track for pyfs\\n2021-03-24 20:03:02,715|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2021-03-24 20:03:02,715|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /tmp/azureml_runs/mslearn-train-diabetes_1616616163_599b8229\\n2021-03-24 20:03:02,715|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from /tmp/azureml_runs/mslearn-train-diabetes_1616616163_599b8229 to /tmp/azureml_runs/mslearn-train-diabetes_1616616163_599b8229\\n2021-03-24 20:03:02,715|azureml.history._tracking.PythonWorkingDirectory|INFO|Working dir is already updated /tmp/azureml_runs/mslearn-train-diabetes_1616616163_599b8229\\n2021-03-24 20:03:02,715|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\n2021-03-24 20:03:02,715|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\n2021-03-24 20:03:02,715|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Uploading tracked directories: ['./outputs'], excluding ['azureml-logs/driver_log']\\n2021-03-24 20:03:02,715|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling track for pyfs\\n2021-03-24 20:03:02,715|azureml.history._tracking.PythonWorkingDirectory|DEBUG|./outputs exists as directory, uploading..\\n2021-03-24 20:03:02,715|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Found and adding path to upload: ./outputs/diabetes_model.pkl\\n2021-03-24 20:03:02,715|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Paths to upload is ['./outputs/diabetes_model.pkl'] in dir ./outputs\\n2021-03-24 20:03:02,715|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Overriding default timeout to 300\\n2021-03-24 20:03:02,715|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|[Start]\\n2021-03-24 20:03:02,716|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2021-03-24 20:03:02,716|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2021-03-24 20:03:02,877|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2021-03-24 20:03:02,877|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: perform_upload\\n2021-03-24 20:03:02,878|azureml._restclient.clientbase|DEBUG|ClientBase: Calling create_blob_from_stream with url None\\n2021-03-24 20:03:02,878|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload|DEBUG|Using basic handler - no exception handling\\n2021-03-24 20:03:02,878|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Adding task 0_perform_upload to queue of approximate size: 0\\n2021-03-24 20:03:02,878|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|[Stop] - waiting default timeout\\n2021-03-24 20:03:02,879|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|[START]\\n2021-03-24 20:03:02,879|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|Overriding default flush timeout from None to 300\\n2021-03-24 20:03:02,879|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|Waiting 300 seconds on tasks: [AsyncTask(0_perform_upload)].\\n2021-03-24 20:03:02,936|azureml._file_utils.upload|DEBUG|Uploaded blob ExperimentRun/dcid.mslearn-train-diabetes_1616616163_599b8229/outputs/diabetes_model.pkl with size 964, file size 964.\\n2021-03-24 20:03:03,129|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload.WaitingTask|DEBUG|[START]\\n2021-03-24 20:03:03,129|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload.WaitingTask|DEBUG|Awaiter is upload_files\\n2021-03-24 20:03:03,129|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload.WaitingTask|DEBUG|[STOP]\\n2021-03-24 20:03:03,130|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Waiting on task: 0_perform_upload.\\n1 tasks left. Current duration of flush 6.532669067382812e-05 seconds.\\n\\n2021-03-24 20:03:03,130|azureml._SubmittedRun#mslearn-train-diabetes_1616616163_599b8229.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|[STOP]\\n2021-03-24 20:03:03,130|azureml.TrackFolders|DEBUG|[STOP]\\n2021-03-24 20:03:03,130|azureml._history.utils.context_managers|DEBUG|exiting ContentUploader, waiting for file_watcher to finish upload...\\n2021-03-24 20:03:03,130|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher called finish, setting event\\n2021-03-24 20:03:03,130|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher received exit event, getting current_stat\\n2021-03-24 20:03:03,131|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2021-03-24 20:03:03,135|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result|DEBUG|Using basic handler - no exception handling\\n2021-03-24 20:03:03,135|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 3_result to queue of approximate size: 3\\n2021-03-24 20:03:03,135|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher retrieved current_stat, will upload to current_stat\\n2021-03-24 20:03:03,135|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:03:03,135|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:03:03,136|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:03:03,136|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:03:03,136|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:03:03,136|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:03:03,136|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:03:03,137|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:03:03,137|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:03:03,137|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:03:03,137|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:03:03,138|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:03:03,138|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:03:03,138|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:03:03,138|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:03:03,138|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:03:03,139|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:03:03,139|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:03:03,139|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:03:03,139|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:03:03,139|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:03:03,140|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:03:03,140|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:03:03,140|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:03:03,140|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:03:03,141|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:03:03,141|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:03:03,141|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:03:03,141|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:03:03,141|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:03:03,142|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:03:03,142|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-03-24 20:03:03,143|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2021-03-24 20:03:03,148|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result|DEBUG|Using basic handler - no exception handling\\n2021-03-24 20:03:03,148|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 4_result to queue of approximate size: 4\\n2021-03-24 20:03:03,148|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher finished uploading to current_stat, finishing task queue\\n2021-03-24 20:03:03,148|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|[Stop] - waiting default timeout\\n2021-03-24 20:03:03,148|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|[START]\\n2021-03-24 20:03:03,148|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|Overriding default flush timeout from None to 120\\n2021-03-24 20:03:03,148|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0_result), AsyncTask(1_result), AsyncTask(2_result), AsyncTask(3_result), AsyncTask(4_result)].\\n2021-03-24 20:03:03,148|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|[START]\\n2021-03-24 20:03:03,148|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2021-03-24 20:03:03,148|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|[STOP]\\n2021-03-24 20:03:03,148|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|[START]\\n2021-03-24 20:03:03,148|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2021-03-24 20:03:03,149|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|[STOP]\\n2021-03-24 20:03:03,149|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|[START]\\n2021-03-24 20:03:03,149|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2021-03-24 20:03:03,149|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|[STOP]\\n2021-03-24 20:03:03,149|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result.WaitingTask|DEBUG|[START]\\n2021-03-24 20:03:03,149|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2021-03-24 20:03:03,149|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result.WaitingTask|DEBUG|[STOP]\\n2021-03-24 20:03:03,399|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result.WaitingTask|DEBUG|[START]\\n2021-03-24 20:03:03,399|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2021-03-24 20:03:03,399|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result.WaitingTask|DEBUG|[STOP]\\n2021-03-24 20:03:03,399|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Waiting on task: 4_result.\\n1 tasks left. Current duration of flush 0.0005195140838623047 seconds.\\n\\n2021-03-24 20:03:03,399|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|[STOP]\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.22.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'mslearn-train-diabetes_1616616163_599b8229',\n",
       " 'target': 'local',\n",
       " 'status': 'Finalizing',\n",
       " 'startTimeUtc': '2021-03-24T20:02:46.068047Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  'ContentSnapshotId': '90de8ea8-c400-4df8-bd81-64928319ddc8',\n",
       "  'azureml.git.repository_uri': 'https://github.com/MicrosoftLearning/mslearn-dp100',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/MicrosoftLearning/mslearn-dp100',\n",
       "  'azureml.git.branch': 'main',\n",
       "  'mlflow.source.git.branch': 'main',\n",
       "  'azureml.git.commit': 'f239fd89deb74b8808e79f452dab1b737a3c3070',\n",
       "  'mlflow.source.git.commit': 'f239fd89deb74b8808e79f452dab1b737a3c3070',\n",
       "  'azureml.git.dirty': 'True'},\n",
       " 'inputDatasets': [{'dataset': {'id': '6d4f9ad5-a740-46ce-9a04-1d94f1d42114'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'training_files', 'mechanism': 'Download'}}],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'diabetes_training.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--regularization',\n",
       "   '0.1',\n",
       "   '--input-data',\n",
       "   'DatasetConsumptionConfig:training_files'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {},\n",
       "  'data': {'training_files': {'dataLocation': {'dataset': {'id': '6d4f9ad5-a740-46ce-9a04-1d94f1d42114',\n",
       "      'name': 'diabetes file dataset',\n",
       "      'version': '1'},\n",
       "     'dataPath': None},\n",
       "    'mechanism': 'Download',\n",
       "    'environmentVariableName': 'training_files',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False}},\n",
       "  'outputData': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 1,\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'sklearn-env',\n",
       "   'version': 'Autosave_2021-03-24T19:59:40Z_39254d5c',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults~=1.22.0', 'azureml-dataprep[pandas]']},\n",
       "      'scikit-learn',\n",
       "      'pip'],\n",
       "     'name': 'azureml_2f7b943ce285cfcb7487460b5c8d4fe6'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210104.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': None,\n",
       "   'imageVersion': None,\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None,\n",
       "   'virtualClusterArmId': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': False,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {}},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://azuredschallen0050415378.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1616616163_599b8229/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=RLVW%2FQE2kEzd9ly2UURg8awHUO8jifya3wWpkKD39UU%3D&st=2021-03-24T19%3A53%3A02Z&se=2021-03-25T04%3A03%3A02Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://azuredschallen0050415378.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1616616163_599b8229/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=nnWv2LA4eawxSuWpiRrYHNaOqWYxhK4Olmzo%2FiyPfEI%3D&st=2021-03-24T19%3A53%3A02Z&se=2021-03-25T04%3A03%3A02Z&sp=r',\n",
       "  'logs/azureml/30422_azureml.log': 'https://azuredschallen0050415378.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1616616163_599b8229/logs/azureml/30422_azureml.log?sv=2019-02-02&sr=b&sig=ZiRHcy9wtiIzTUf7dY9Iyu7gBe3e%2Fzq7TvXA5e5ytFA%3D&st=2021-03-24T19%3A52%3A57Z&se=2021-03-25T04%3A02%3A57Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess.log': 'https://azuredschallen0050415378.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1616616163_599b8229/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=4RITgtgQoilIzWTSYoM5kEI8d4dkDHy%2F%2FidCnH7nUjU%3D&st=2021-03-24T19%3A52%3A57Z&se=2021-03-25T04%3A02%3A57Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://azuredschallen0050415378.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-diabetes_1616616163_599b8229/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=wPWYmu6pLWD8JkMm5D5jFmAHikI0YAQnDaY5myBMoB4%3D&st=2021-03-24T19%3A52%3A57Z&se=2021-03-25T04%3A02%3A57Z&sp=r'},\n",
       " 'submittedBy': 'Chidi Ndego'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "\n",
    "# Get the training dataset\n",
    "diabetes_ds = ws.datasets.get(\"diabetes file dataset\")\n",
    "\n",
    "# Create a script config\n",
    "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
    "                                script='diabetes_training.py',\n",
    "                                arguments = ['--regularization', 0.1, # Regularizaton rate parameter\n",
    "                                             '--input-data', diabetes_ds.as_named_input('training_files').as_download()], # Reference to dataset location\n",
    "                                environment=sklearn_env) # Use the environment created previously\n",
    "\n",
    "# submit the experiment\n",
    "experiment_name = 'mslearn-train-diabetes'\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)\n",
    "run = experiment.submit(config=script_config)\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the experiment has completed, in the widget, view the **azureml-logs/70_driver_log.txt** output log to verify that the files in the file dataset were downloaded to a temporary folder to enable the script to read the files.\n",
    "\n",
    "### Register the trained model\n",
    "\n",
    "Once again, you can register the model that was trained by the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_model version: 4\n",
      "\t Training context : File dataset\n",
      "\t AUC : 0.8568517900798176\n",
      "\t Accuracy : 0.7891111111111111\n",
      "\n",
      "\n",
      "diabetes_model version: 3\n",
      "\t Training context : Tabular dataset\n",
      "\t AUC : 0.8568595320655352\n",
      "\t Accuracy : 0.7891111111111111\n",
      "\n",
      "\n",
      "diabetes_model version: 2\n",
      "\t Training context : Parameterized script\n",
      "\t AUC : 0.8484357430717946\n",
      "\t Accuracy : 0.774\n",
      "\n",
      "\n",
      "diabetes_model version: 1\n",
      "\t Training context : Script\n",
      "\t AUC : 0.8483203144435048\n",
      "\t Accuracy : 0.774\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
    "                   tags={'Training context':'File dataset'}, properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
    "\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **More Information**: For more information about training with datasets, see [Training with Datasets](https://docs.microsoft.com/azure/machine-learning/how-to-train-with-datasets) in the Azure ML documentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
